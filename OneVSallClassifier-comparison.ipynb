{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcce19ed",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "- Fit a One vs All classifier for for different types of variable stars\n",
    "- Use several different classifier methods: Random Forest, Decision Tree, Logistic Regression, Naive Bayes\n",
    "- Create a comparision table for different classifiers and labels. Compare using metrics like accuracy, precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cdab3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ff13e0",
   "metadata": {},
   "source": [
    "## Complete features and label table from Xiadian's website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f99040f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BYDra' 'EW' 'SR' 'RSCVN' 'RR' 'DSCT' 'EA' 'Mira' 'RRc' 'CEP']\n"
     ]
    }
   ],
   "source": [
    "widths = (8,7,4,13,43)\n",
    "header_pd = pd.read_fwf('Labeled_data.txt', widths = widths,skiprows=7, nrows=27)\n",
    "labeled_data = pd.read_csv('Labeled_data.txt', header=None, delim_whitespace=True, skiprows=36) # extract data\n",
    "labeled_data.columns = header_pd.iloc[:,3]\n",
    "labeled_data.head()\n",
    "label = labeled_data.Type.unique()\n",
    "label = np.delete(label, np.where(label == 'CEPII')) # CEPII has very few samples so we ignore it\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12dbb2a",
   "metadata": {},
   "source": [
    "## Import features extracted from light curves\n",
    "These features are caluclated on 1000 light curves of each variable type. The light curves are imported from variables.cn:88/\n",
    "Feature list\n",
    "- mean : mean of the light curve\n",
    "- wmean : weight mean of the light curve\n",
    "- MAD : deviation about the median\n",
    "- IQR : inter quartile percentile of the light curve\n",
    "- f60 : 60 percentile  of light curve\n",
    "- f70 : 70 percentile of the light curve\n",
    "- f80 : 80 percentile of the light curve\n",
    "- f90 : 90 percentile of the light curve\n",
    "- skew : skewness of the light curve\n",
    "- kurtosis : kurtosis of the light curve\n",
    "- welsk_k, welsh_j : welsh and staton J and K statistics of the light curve\n",
    "- g_ : g band filter\n",
    "- r_ : r band filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6847d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('features10000.csv', header=None, skiprows=1)\n",
    "header = pd.read_csv('features10000.csv', header=None, nrows=1)\n",
    "df.columns = header.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25639401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sourceid</th>\n",
       "      <th>ID</th>\n",
       "      <th>RAdeg</th>\n",
       "      <th>DEdeg</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>g_wmean</th>\n",
       "      <th>g_MAD</th>\n",
       "      <th>g_IQR</th>\n",
       "      <th>g_f60</th>\n",
       "      <th>g_f70</th>\n",
       "      <th>...</th>\n",
       "      <th>r_IQR</th>\n",
       "      <th>r_f60</th>\n",
       "      <th>r_f70</th>\n",
       "      <th>r_f80</th>\n",
       "      <th>r_f90</th>\n",
       "      <th>r_skew</th>\n",
       "      <th>r_kurtosis</th>\n",
       "      <th>r_welsh_J</th>\n",
       "      <th>r_welsh_K</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ZTFJ000000.13+620605.8</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>62.101631</td>\n",
       "      <td>17.994656</td>\n",
       "      <td>17.992102</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.07000</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05125</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>0.06655</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.09370</td>\n",
       "      <td>0.105202</td>\n",
       "      <td>-0.632720</td>\n",
       "      <td>40.723268</td>\n",
       "      <td>1678.291273</td>\n",
       "      <td>BYDra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ZTFJ000000.14+721413.7</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>72.237174</td>\n",
       "      <td>19.619402</td>\n",
       "      <td>19.579923</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.22650</td>\n",
       "      <td>0.2850</td>\n",
       "      <td>0.35950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22750</td>\n",
       "      <td>0.2712</td>\n",
       "      <td>0.30765</td>\n",
       "      <td>0.3614</td>\n",
       "      <td>0.44115</td>\n",
       "      <td>0.334634</td>\n",
       "      <td>-0.775188</td>\n",
       "      <td>258.579275</td>\n",
       "      <td>3360.702573</td>\n",
       "      <td>EW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>ZTFJ000000.19+320847.2</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>32.146449</td>\n",
       "      <td>15.313984</td>\n",
       "      <td>15.313984</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.14200</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.18300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.16080</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>0.18860</td>\n",
       "      <td>-0.212606</td>\n",
       "      <td>-1.485137</td>\n",
       "      <td>171.745322</td>\n",
       "      <td>891.052032</td>\n",
       "      <td>EW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>ZTFJ000000.26+311206.3</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>31.201756</td>\n",
       "      <td>16.353295</td>\n",
       "      <td>16.353295</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.14900</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.18700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10200</td>\n",
       "      <td>0.1322</td>\n",
       "      <td>0.15980</td>\n",
       "      <td>0.1946</td>\n",
       "      <td>0.20560</td>\n",
       "      <td>0.418285</td>\n",
       "      <td>-1.009552</td>\n",
       "      <td>202.025570</td>\n",
       "      <td>966.503331</td>\n",
       "      <td>EW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>ZTFJ000000.30+233400.5</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>23.566828</td>\n",
       "      <td>17.892283</td>\n",
       "      <td>17.878715</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.18975</td>\n",
       "      <td>0.2526</td>\n",
       "      <td>0.28225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22900</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.29620</td>\n",
       "      <td>0.3132</td>\n",
       "      <td>0.33620</td>\n",
       "      <td>0.158998</td>\n",
       "      <td>-1.484462</td>\n",
       "      <td>253.787215</td>\n",
       "      <td>1019.579800</td>\n",
       "      <td>EW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0  sourceid                      ID     RAdeg      DEdeg     g_mean  \\\n",
       "0       1.0  ZTFJ000000.13+620605.8  0.000566  62.101631  17.994656   \n",
       "1       2.0  ZTFJ000000.14+721413.7  0.000620  72.237174  19.619402   \n",
       "2       3.0  ZTFJ000000.19+320847.2  0.000795  32.146449  15.313984   \n",
       "3       4.0  ZTFJ000000.26+311206.3  0.001085  31.201756  16.353295   \n",
       "4       6.0  ZTFJ000000.30+233400.5  0.001249  23.566828  17.892283   \n",
       "\n",
       "0    g_wmean  g_MAD    g_IQR   g_f60    g_f70  ...    r_IQR   r_f60    r_f70  \\\n",
       "0  17.992102  0.034  0.07000  0.0820  0.10000  ...  0.05125  0.0580  0.06655   \n",
       "1  19.579923  0.111  0.22650  0.2850  0.35950  ...  0.22750  0.2712  0.30765   \n",
       "2  15.313984  0.072  0.14200  0.1580  0.18300  ...  0.12600  0.1470  0.16080   \n",
       "3  16.353295  0.077  0.14900  0.1710  0.18700  ...  0.10200  0.1322  0.15980   \n",
       "4  17.878715  0.102  0.18975  0.2526  0.28225  ...  0.22900  0.2700  0.29620   \n",
       "\n",
       "0   r_f80    r_f90    r_skew  r_kurtosis   r_welsh_J    r_welsh_K   Type  \n",
       "0  0.0797  0.09370  0.105202   -0.632720   40.723268  1678.291273  BYDra  \n",
       "1  0.3614  0.44115  0.334634   -0.775188  258.579275  3360.702573     EW  \n",
       "2  0.1760  0.18860 -0.212606   -1.485137  171.745322   891.052032     EW  \n",
       "3  0.1946  0.20560  0.418285   -1.009552  202.025570   966.503331     EW  \n",
       "4  0.3132  0.33620  0.158998   -1.484462  253.787215  1019.579800     EW  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc7a1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with Blank values\n",
    "df.replace('', np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497e4ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BYDra' 'EW' 'SR' 'RSCVN' 'RR' 'DSCT' 'EA' 'RRc' 'Mira' 'CEP']\n"
     ]
    }
   ],
   "source": [
    "# get all unique labels\n",
    "label = df.Type.unique()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e0c17f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Type', ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram of variable types in the dataset\n",
    "import seaborn as sns\n",
    "sns.histplot(data=df, x=df.Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3525419",
   "metadata": {},
   "source": [
    "## Various functions to create multiple classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "261ae79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_to_2labels(df,variable_type):\n",
    "    \"\"\"\n",
    "    converts multiple labels for diffrent variable types to only two labels for one vs all classifier.\n",
    "    Returns 2 data frames: \n",
    "    1. Original data frame with new labels. \n",
    "    2. Dataframe with equal candidates of the two classes.\n",
    "    \"\"\"\n",
    "    OneClass = variable_type\n",
    "    df0 = df.copy()\n",
    "    df0.loc[df0.Type != OneClass,'Type'] = 'Other'\n",
    "    df1 = df0[df0.Type == 'Other']\n",
    "    df2 = df0[df0.Type == OneClass]\n",
    "\n",
    "    df3 = df1.sample(n=1000, random_state=1) # balance data type by only selecting 1000 of other type\n",
    "    frames = [df2,df3]\n",
    "    df_onevsall = pd.concat(frames)\n",
    "    return df0, df_onevsall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f12dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess data for one vs all classifier and split it to train/test data\n",
    "    \"\"\"\n",
    "    # Map string labels to numbers\n",
    "    label = df.Type\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(label)\n",
    "\n",
    "    # Drop columns that are not features\n",
    "    X = df\n",
    "    # Encode labels to form y labels\n",
    "    y = le.transform(df.Type)\n",
    "\n",
    "    # Split dataset into training set and test set\n",
    "    X_tr, X_ts, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "    X_train = X_tr.drop(['Type','sourceid', 'RAdeg','DEdeg','ID'],axis='columns')\n",
    "    X_test = X_ts.drop(['Type','sourceid', 'RAdeg','DEdeg','ID'],axis='columns')\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a568c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "def oneVSall_classiffier(name,model,X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train Classifier using train dataset. Calculate classifier metrics using test dataset\n",
    "    \"\"\"\n",
    "    #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    # Predict test data output\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Estimate model performance on test data\n",
    "    if name == \"Isolation Forest\":\n",
    "        one_index = np.where(y_pred==1)\n",
    "        y_pred[one_index] = 1\n",
    "        negone_index = np.where(y_pred==-1)\n",
    "        y_pred[negone_index] = 0\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred)\n",
    "    recall = metrics.recall_score(y_test, y_pred)\n",
    "                                      \n",
    "    return clf, accuracy, precision, recall, confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e7eb9",
   "metadata": {},
   "source": [
    "## Train and Compare Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efa98587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of classification methods\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "names = [\"XG Boost\",\"Random Forest\", \"Decision Tree\", \"Logistic Regression\", \"Naive Bayes\", \"Isolation Forest\"]\n",
    "\n",
    "classifiers = [\n",
    "    XGBClassifier(),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    DecisionTreeClassifier(criterion=\"gini\", max_depth=3),\n",
    "    LogisticRegression(max_iter = 500),\n",
    "    GaussianNB(),\n",
    "    IsolationForest()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b633b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG Boost\n",
      "BYDra\n",
      "[22:23:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EW\n",
      "[22:23:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR\n",
      "[22:23:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSCVN\n",
      "[22:23:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR\n",
      "[22:23:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSCT\n",
      "[22:23:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EA\n",
      "[22:23:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRc\n",
      "[22:23:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mira\n",
      "[22:23:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEP\n",
      "[22:23:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "BYDra\n",
      "EW\n",
      "SR\n",
      "RSCVN\n",
      "RR\n",
      "DSCT\n",
      "EA\n",
      "RRc\n",
      "Mira\n",
      "CEP\n",
      "Decision Tree\n",
      "BYDra\n",
      "EW\n",
      "SR\n",
      "RSCVN\n",
      "RR\n",
      "DSCT\n",
      "EA\n",
      "RRc\n",
      "Mira\n",
      "CEP\n",
      "Logistic Regression\n",
      "BYDra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSCVN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSCT\n",
      "EA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mira\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "BYDra\n",
      "EW\n",
      "SR\n",
      "RSCVN\n",
      "RR\n",
      "DSCT\n",
      "EA\n",
      "RRc\n",
      "Mira\n",
      "CEP\n",
      "Isolation Forest\n",
      "BYDra\n",
      "EW\n",
      "SR\n",
      "RSCVN\n",
      "RR\n",
      "DSCT\n",
      "EA\n",
      "RRc\n",
      "Mira\n",
      "CEP\n"
     ]
    }
   ],
   "source": [
    "# Run loop to train all classifiers and collect metrics in a dataframe\n",
    "accuracy ={}\n",
    "precision = {}\n",
    "recall = {}\n",
    "confusion ={}\n",
    "\n",
    "# create comparision dataframe\n",
    "header = pd.MultiIndex.from_product([names,\n",
    "                                     ['accuracy','precision','recall']],\n",
    "                                    names=['classifier','metric'])\n",
    "index_label = label\n",
    "pd_comparison = pd.DataFrame(data=None, index=index_label, columns=header, dtype=None, copy=False)\n",
    "\n",
    "# train models and collect metrics on test data\n",
    "for name, clf in zip(names, classifiers): # loop over different classifiers\n",
    "    print(name)\n",
    "    accuracy[name] = {}\n",
    "    precision[name] = {}\n",
    "    recall[name] = {}\n",
    "    confusion[name] ={}\n",
    "    for variable_type in label: #loop over different types of variable stars\n",
    "        print(variable_type)\n",
    "        df0, df_onevsall = multiple_to_2labels(df,variable_type)\n",
    "        X_train, X_test, y_train, y_test = preprocess_data(df0)\n",
    "        clf, accuracy[name][variable_type],precision[name][variable_type],recall[name][variable_type], confusion[name][variable_type] = oneVSall_classiffier(name,clf,X_train, X_test, y_train, y_test)\n",
    "    pd_comparison.loc[:,(name,'accuracy')] = list(accuracy[name].values())\n",
    "    pd_comparison.loc[:,(name,'precision')] = list(precision[name].values())\n",
    "    pd_comparison.loc[:,(name,'recall')] = list(recall[name].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e92cb23c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>classifier</th>\n",
       "      <th colspan=\"3\" halign=\"left\">XG Boost</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Random Forest</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Decision Tree</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Logistic Regression</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Naive Bayes</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Isolation Forest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BYDra</th>\n",
       "      <td>0.902511</td>\n",
       "      <td>0.925764</td>\n",
       "      <td>0.968037</td>\n",
       "      <td>0.897341</td>\n",
       "      <td>0.905653</td>\n",
       "      <td>0.987094</td>\n",
       "      <td>0.893648</td>\n",
       "      <td>0.893648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886263</td>\n",
       "      <td>0.889632</td>\n",
       "      <td>0.995426</td>\n",
       "      <td>0.538405</td>\n",
       "      <td>0.988206</td>\n",
       "      <td>0.486924</td>\n",
       "      <td>0.804653</td>\n",
       "      <td>0.885540</td>\n",
       "      <td>0.897605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EW</th>\n",
       "      <td>0.938331</td>\n",
       "      <td>0.952497</td>\n",
       "      <td>0.979132</td>\n",
       "      <td>0.940177</td>\n",
       "      <td>0.947970</td>\n",
       "      <td>0.987680</td>\n",
       "      <td>0.887001</td>\n",
       "      <td>0.887288</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.888479</td>\n",
       "      <td>0.898605</td>\n",
       "      <td>0.986347</td>\n",
       "      <td>0.279542</td>\n",
       "      <td>0.995960</td>\n",
       "      <td>0.201884</td>\n",
       "      <td>0.793575</td>\n",
       "      <td>0.877501</td>\n",
       "      <td>0.892442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SR</th>\n",
       "      <td>0.958641</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.600840</td>\n",
       "      <td>0.954210</td>\n",
       "      <td>0.903846</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>0.922083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.943870</td>\n",
       "      <td>0.795775</td>\n",
       "      <td>0.478814</td>\n",
       "      <td>0.250369</td>\n",
       "      <td>0.097670</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.178360</td>\n",
       "      <td>0.093213</td>\n",
       "      <td>0.970213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSCVN</th>\n",
       "      <td>0.903988</td>\n",
       "      <td>0.624242</td>\n",
       "      <td>0.342193</td>\n",
       "      <td>0.903250</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.889586</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.070968</td>\n",
       "      <td>0.889217</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.491507</td>\n",
       "      <td>0.165031</td>\n",
       "      <td>0.943860</td>\n",
       "      <td>0.200886</td>\n",
       "      <td>0.118271</td>\n",
       "      <td>0.993151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RR</th>\n",
       "      <td>0.968981</td>\n",
       "      <td>0.871698</td>\n",
       "      <td>0.822064</td>\n",
       "      <td>0.957903</td>\n",
       "      <td>0.832599</td>\n",
       "      <td>0.713208</td>\n",
       "      <td>0.936854</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.469965</td>\n",
       "      <td>0.944978</td>\n",
       "      <td>0.770563</td>\n",
       "      <td>0.649635</td>\n",
       "      <td>0.704579</td>\n",
       "      <td>0.263747</td>\n",
       "      <td>0.965870</td>\n",
       "      <td>0.197932</td>\n",
       "      <td>0.118078</td>\n",
       "      <td>0.979730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSCT</th>\n",
       "      <td>0.926514</td>\n",
       "      <td>0.941551</td>\n",
       "      <td>0.978512</td>\n",
       "      <td>0.920606</td>\n",
       "      <td>0.930078</td>\n",
       "      <td>0.985106</td>\n",
       "      <td>0.896233</td>\n",
       "      <td>0.908745</td>\n",
       "      <td>0.983135</td>\n",
       "      <td>0.888479</td>\n",
       "      <td>0.900385</td>\n",
       "      <td>0.981963</td>\n",
       "      <td>0.404727</td>\n",
       "      <td>0.989336</td>\n",
       "      <td>0.342494</td>\n",
       "      <td>0.779911</td>\n",
       "      <td>0.875207</td>\n",
       "      <td>0.877390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EA</th>\n",
       "      <td>0.983383</td>\n",
       "      <td>0.988396</td>\n",
       "      <td>0.992923</td>\n",
       "      <td>0.975997</td>\n",
       "      <td>0.985173</td>\n",
       "      <td>0.988021</td>\n",
       "      <td>0.972304</td>\n",
       "      <td>0.982217</td>\n",
       "      <td>0.986705</td>\n",
       "      <td>0.973412</td>\n",
       "      <td>0.981474</td>\n",
       "      <td>0.988801</td>\n",
       "      <td>0.425406</td>\n",
       "      <td>0.991908</td>\n",
       "      <td>0.356460</td>\n",
       "      <td>0.817578</td>\n",
       "      <td>0.892828</td>\n",
       "      <td>0.904624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RRc</th>\n",
       "      <td>0.963072</td>\n",
       "      <td>0.890196</td>\n",
       "      <td>0.759197</td>\n",
       "      <td>0.954948</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.665493</td>\n",
       "      <td>0.939808</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.451852</td>\n",
       "      <td>0.942024</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.617544</td>\n",
       "      <td>0.675037</td>\n",
       "      <td>0.236220</td>\n",
       "      <td>0.974729</td>\n",
       "      <td>0.191285</td>\n",
       "      <td>0.106531</td>\n",
       "      <td>0.996183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mira</th>\n",
       "      <td>0.997415</td>\n",
       "      <td>0.998805</td>\n",
       "      <td>0.998407</td>\n",
       "      <td>0.996307</td>\n",
       "      <td>0.997609</td>\n",
       "      <td>0.998404</td>\n",
       "      <td>0.997415</td>\n",
       "      <td>0.998010</td>\n",
       "      <td>0.999203</td>\n",
       "      <td>0.998523</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>0.998810</td>\n",
       "      <td>0.986337</td>\n",
       "      <td>0.999594</td>\n",
       "      <td>0.985594</td>\n",
       "      <td>0.983013</td>\n",
       "      <td>0.999593</td>\n",
       "      <td>0.982007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEP</th>\n",
       "      <td>0.971935</td>\n",
       "      <td>0.976209</td>\n",
       "      <td>0.993543</td>\n",
       "      <td>0.960118</td>\n",
       "      <td>0.964595</td>\n",
       "      <td>0.992713</td>\n",
       "      <td>0.922083</td>\n",
       "      <td>0.933156</td>\n",
       "      <td>0.985955</td>\n",
       "      <td>0.941285</td>\n",
       "      <td>0.953870</td>\n",
       "      <td>0.983474</td>\n",
       "      <td>0.516617</td>\n",
       "      <td>0.985750</td>\n",
       "      <td>0.476499</td>\n",
       "      <td>0.826809</td>\n",
       "      <td>0.908462</td>\n",
       "      <td>0.901494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "classifier  XG Boost                     Random Forest                      \\\n",
       "metric      accuracy precision    recall      accuracy precision    recall   \n",
       "BYDra       0.902511  0.925764  0.968037      0.897341  0.905653  0.987094   \n",
       "EW          0.938331  0.952497  0.979132      0.940177  0.947970  0.987680   \n",
       "SR          0.958641  0.893750  0.600840      0.954210  0.903846  0.451923   \n",
       "RSCVN       0.903988  0.624242  0.342193      0.903250  0.648148  0.238095   \n",
       "RR          0.968981  0.871698  0.822064      0.957903  0.832599  0.713208   \n",
       "DSCT        0.926514  0.941551  0.978512      0.920606  0.930078  0.985106   \n",
       "EA          0.983383  0.988396  0.992923      0.975997  0.985173  0.988021   \n",
       "RRc         0.963072  0.890196  0.759197      0.954948  0.875000  0.665493   \n",
       "Mira        0.997415  0.998805  0.998407      0.996307  0.997609  0.998404   \n",
       "CEP         0.971935  0.976209  0.993543      0.960118  0.964595  0.992713   \n",
       "\n",
       "classifier Decision Tree                     Logistic Regression            \\\n",
       "metric          accuracy precision    recall            accuracy precision   \n",
       "BYDra           0.893648  0.893648  1.000000            0.886263  0.889632   \n",
       "EW              0.887001  0.887288  0.999584            0.888479  0.898605   \n",
       "SR              0.922083  0.000000  0.000000            0.943870  0.795775   \n",
       "RSCVN           0.889586  0.666667  0.070968            0.889217  0.428571   \n",
       "RR              0.936854  0.863636  0.469965            0.944978  0.770563   \n",
       "DSCT            0.896233  0.908745  0.983135            0.888479  0.900385   \n",
       "EA              0.972304  0.982217  0.986705            0.973412  0.981474   \n",
       "RRc             0.939808  0.890511  0.451852            0.942024  0.785714   \n",
       "Mira            0.997415  0.998010  0.999203            0.998523  0.999603   \n",
       "CEP             0.922083  0.933156  0.985955            0.941285  0.953870   \n",
       "\n",
       "classifier           Naive Bayes                     Isolation Forest  \\\n",
       "metric        recall    accuracy precision    recall         accuracy   \n",
       "BYDra       0.995426    0.538405  0.988206  0.486924         0.804653   \n",
       "EW          0.986347    0.279542  0.995960  0.201884         0.793575   \n",
       "SR          0.478814    0.250369  0.097670  0.931624         0.178360   \n",
       "RSCVN       0.030303    0.491507  0.165031  0.943860         0.200886   \n",
       "RR          0.649635    0.704579  0.263747  0.965870         0.197932   \n",
       "DSCT        0.981963    0.404727  0.989336  0.342494         0.779911   \n",
       "EA          0.988801    0.425406  0.991908  0.356460         0.817578   \n",
       "RRc         0.617544    0.675037  0.236220  0.974729         0.191285   \n",
       "Mira        0.998810    0.986337  0.999594  0.985594         0.983013   \n",
       "CEP         0.983474    0.516617  0.985750  0.476499         0.826809   \n",
       "\n",
       "classifier                      \n",
       "metric     precision    recall  \n",
       "BYDra       0.885540  0.897605  \n",
       "EW          0.877501  0.892442  \n",
       "SR          0.093213  0.970213  \n",
       "RSCVN       0.118271  0.993151  \n",
       "RR          0.118078  0.979730  \n",
       "DSCT        0.875207  0.877390  \n",
       "EA          0.892828  0.904624  \n",
       "RRc         0.106531  0.996183  \n",
       "Mira        0.999593  0.982007  \n",
       "CEP         0.908462  0.901494  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the comparision table\n",
    "pd_comparison.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dcb5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
