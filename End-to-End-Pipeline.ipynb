{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c7d2285",
   "metadata": {},
   "source": [
    "## Scketch an end to end pipeline to run classification models on new data and give predictions.\n",
    "1. Get the light curve\n",
    "    1. get light curve from DR2 set\n",
    "        1. set parametes \n",
    "        1. form url using ZTF API format\n",
    "        1. query URL\n",
    "    1. get light curve from Xiao Dian's dataset\n",
    "        1. set parameters\n",
    "        1. form URL\n",
    "        1. query URL\n",
    "    1. plot flight curve per filter\n",
    "1. Calculate features\n",
    "    1. Take light curve\n",
    "    1. calaculate all features\n",
    "    1. return all features\n",
    "1. Function run all the models with data\n",
    "    1. Load all models\n",
    "    1. pass feature data to all models and get prediction proba\n",
    "    1. Return prediction proba for each classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce2699f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle # allows to save differnt trained models of the same classifier object\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2217d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_lightcurve_XD(SourceID): \n",
    "    \"\"\"\n",
    "    Download data for a single source from Xiao Dian's website. Source is identified using SourceID\n",
    "    \"\"\"\n",
    "    url = 'http://variables.cn:88/seldataz.php?SourceID=' + str(SourceID)   \n",
    "    try:\n",
    "        lc = pd.read_csv(url, header='infer')\n",
    "        lc['Type'] = variable_type\n",
    "        lc['ID'] = labeled_data.ID[k]\n",
    "    except:\n",
    "        lc = pd.DataFrame()\n",
    "    return lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f071c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_lightcurve_DR(parameters): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6780977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(mag,mag_err):\n",
    "    mag2 = (mag_err*mag_err) # mag err square\n",
    "    mag2_inv = 1/mag2.values; # take inverse of the values\n",
    "    w = pd.Series(mag2_inv) # covert it back to s series\n",
    "    sw = w.sum() # sum of weights\n",
    "    wmag = mag*w # multiply magnitude with weights\n",
    "    wmean = wmag.sum()/sw # weighted mean\n",
    "    return wmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b950d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# welsh J, K statistics\n",
    "def welsh_staton(mag_series,wmean):\n",
    "    N = len(mag_series)\n",
    "    d_i = N/(N-1)*(mag_series - wmean) # replace mean by weighted mean\n",
    "    d_i1 = d_i.shift(periods=-1)\n",
    "    d_i1.fillna(0, inplace = True)\n",
    "    Pi = d_i*d_i1\n",
    "    Pi_val = Pi.values\n",
    "    Psign = np.sign(Pi_val)\n",
    "    Jval = Psign*np.sqrt(np.abs(Pi_val))\n",
    "    J = np.sum(Jval) \n",
    "    K1 = abs(d_i.values)/N\n",
    "    K2 = np.sqrt(1/N*np.sum(d_i.values*d_i.values))\n",
    "    K = np.sum(K1*K2)\n",
    "    return J, K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b5baae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(lc):\n",
    "    \"\"\"\n",
    "    Calculate features for a light curve passed as a dataframe.\n",
    "    \"\"\"\n",
    "    if len(lc) >1:\n",
    "#         lc.columns = ResultSet[0].keys()\n",
    "#         RA.append(lc.RAdeg[1])\n",
    "#         Dec.append(lc.DEdeg[1])\n",
    "#         SourceID.append(lc.SourceID[1])\n",
    "#         ID.append(lc.ID[1])\n",
    "#         Type.append(lc.Type[1])\n",
    "        \n",
    "        dfg = lc.loc[lc[\"band\"] == \"g\"]\n",
    "        dfr = lc.loc[lc[\"band\"] == \"r\"]\n",
    "        if len(dfg) > 1:\n",
    "            N = len(dfg)\n",
    "    #         wmean_temp = np.average(dfg.mag, weights = dfg.e_mag*dfg.e_mag)\n",
    "            wmean_temp = weighted_mean(dfg.mag,dfg.e_mag)\n",
    "            K_temp, J_temp =  welsh_staton(dfg.mag, wmean_temp )\n",
    "            g_mean.append(dfg.mag.mean())\n",
    "            g_wmean.append(wmean_temp) \n",
    "            deviation = abs(dfg.mag - dfg.mag.median())\n",
    "            g_MAD.append(deviation.median())\n",
    "            g_IQR.append(dfg.mag.quantile(0.75) - dfg.mag.quantile(0.25))\n",
    "            g_f60.append(dfg.mag.quantile(0.80) - dfg.mag.quantile(0.2))\n",
    "            g_f70.append(dfg.mag.quantile(0.85) - dfg.mag.quantile(0.15))\n",
    "            g_f80.append(dfg.mag.quantile(0.9) - dfg.mag.quantile(0.10))\n",
    "            g_f90.append(dfg.mag.quantile(0.95) - dfg.mag.quantile(0.05))\n",
    "            g_skew.append(dfg.mag.skew())\n",
    "            g_kurtosis.append(dfg.mag.kurtosis())\n",
    "            g_welsh_J.append(J_temp)\n",
    "            g_welsh_K.append(K_temp)\n",
    "        else:\n",
    "            g_mean.append(np.NaN)\n",
    "            g_wmean.append(np.NaN) \n",
    "            g_MAD.append(np.NaN)\n",
    "            g_IQR.append(np.NaN)\n",
    "            g_f60.append(np.NaN)\n",
    "            g_f70.append(np.NaN)\n",
    "            g_f80.append(np.NaN)\n",
    "            g_f90.append(np.NaN)\n",
    "            g_skew.append(np.NaN)\n",
    "            g_kurtosis.append(np.NaN)\n",
    "            g_welsh_J.append(np.NaN)\n",
    "            g_welsh_K.append(np.NaN)\n",
    "                \n",
    "        if len(dfr) >1:\n",
    "            N = len(dfr)\n",
    "            wmean_temp = weighted_mean(dfr.mag,dfr.e_mag)\n",
    "    #         wmean_temp = np.average(dfr.mag, weights = dfr.e_mag*dfr.e_mag)\n",
    "            K_temp, J_temp =  welsh_staton(dfr.mag, wmean_temp )\n",
    "            r_mean.append(dfr.mag.mean())\n",
    "            r_wmean.append(wmean_temp) \n",
    "            deviation = abs(dfr.mag - dfr.mag.median())\n",
    "            r_MAD.append(deviation.median())\n",
    "            r_IQR.append(dfr.mag.quantile(0.75) - dfr.mag.quantile(0.25))\n",
    "            r_f60.append(dfr.mag.quantile(0.80) - dfr.mag.quantile(0.2))\n",
    "            r_f70.append(dfr.mag.quantile(0.85) - dfr.mag.quantile(0.15))\n",
    "            r_f80.append(dfr.mag.quantile(0.9) - dfr.mag.quantile(0.10))\n",
    "            r_f90.append(dfr.mag.quantile(0.95) - dfr.mag.quantile(0.05))\n",
    "            r_skew.append(dfr.mag.skew())\n",
    "            r_kurtosis.append(dfr.mag.kurtosis())\n",
    "            r_welsh_J.append(J_temp)\n",
    "            r_welsh_K.append(K_temp)\n",
    "        else:\n",
    "            r_mean.append(np.NaN)\n",
    "            r_wmean.append(np.NaN) \n",
    "            r_MAD.append(np.NaN)\n",
    "            r_IQR.append(np.NaN)\n",
    "            r_f60.append(np.NaN)\n",
    "            r_f70.append(np.NaN)\n",
    "            r_f80.append(np.NaN)\n",
    "            r_f90.append(np.NaN)\n",
    "            r_skew.append(np.NaN)\n",
    "            r_kurtosis.append(np.NaN)\n",
    "            r_welsh_J.append(np.NaN)\n",
    "            r_welsh_K.append(np.NaN)\n",
    "\n",
    "    else:\n",
    "        RA.append(np.NaN)\n",
    "        Dec.append(np.NaN)\n",
    "        SourceID.append(np.NaN) \n",
    "        ID.append(np.NaN)\n",
    "        Type.append(np.NaN)\n",
    "        g_mean.append(np.NaN)\n",
    "        g_wmean.append(np.NaN) \n",
    "        g_MAD.append(np.NaN)\n",
    "        g_IQR.append(np.NaN)\n",
    "        g_f60.append(np.NaN)\n",
    "        g_f70.append(np.NaN)\n",
    "        g_f80.append(np.NaN)\n",
    "        g_f90.append(np.NaN)\n",
    "        g_skew.append(np.NaN)\n",
    "        g_kurtosis.append(np.NaN)\n",
    "        g_welsh_J.append(np.NaN)\n",
    "        g_welsh_K.append(np.NaN)\n",
    "        r_mean.append(np.NaN)\n",
    "        r_wmean.append(np.NaN) \n",
    "        r_MAD.append(np.NaN)\n",
    "        r_IQR.append(np.NaN) \n",
    "        r_f60.append(np.NaN)\n",
    "        r_f70.append(np.NaN)\n",
    "        r_f80.append(np.NaN)\n",
    "        r_f90.append(np.NaN)\n",
    "        r_skew.append(np.NaN)\n",
    "        r_kurtosis.append(np.NaN)\n",
    "        r_welsh_J.append(np.NaN)\n",
    "        r_welsh_K.append(np.NaN)\n",
    "        \n",
    "    # del features\n",
    "    features = pd.DataFrame()\n",
    "    N = 1\n",
    "#     features['sourceid'] = SourceID[0:N]\n",
    "#     features['ID'] = ID[0:N]\n",
    "    # features['ID'] = labeled_data_sampled.ID.values[0:N]\n",
    "#     features['RAdeg'] = RA[0:N]\n",
    "#     features['DEdeg'] = Dec[0:N]\n",
    "\n",
    "    # g filter data\n",
    "    features['g_mean'] = g_mean[0:N]\n",
    "    features['g_wmean'] = g_wmean[0:N]\n",
    "    features['g_MAD'] = g_MAD[0:N]\n",
    "    features['g_IQR'] = g_IQR[0:N]\n",
    "    features['g_f60'] = g_f60[0:N]\n",
    "    features['g_f70'] = g_f70[0:N]\n",
    "    features['g_f80'] = g_f80[0:N]\n",
    "    features['g_f90'] = g_f90[0:N]\n",
    "    features['g_skew'] = g_skew[0:N]\n",
    "    features['g_kurtosis'] = g_kurtosis[0:N]\n",
    "    features['g_welsh_J'] = g_welsh_J[0:N]\n",
    "    features['g_welsh_K'] = g_welsh_K[0:N]\n",
    "\n",
    "    # r filter data\n",
    "    features['r_mean'] = r_mean[0:N]\n",
    "    features['r_wmean'] = r_wmean[0:N]\n",
    "    features['r_MAD'] = r_MAD[0:N]\n",
    "    features['r_IQR'] = r_IQR[0:N]\n",
    "    features['r_f60'] = r_f60[0:N]\n",
    "    features['r_f70'] = r_f70[0:N]\n",
    "    features['r_f80'] = r_f80[0:N]\n",
    "    features['r_f90'] = r_f90[0:N]\n",
    "    features['r_skew'] = r_skew[0:N]\n",
    "    features['r_kurtosis'] = r_kurtosis[0:N]\n",
    "    features['r_welsh_J'] = r_welsh_J[0:N]\n",
    "    features['r_welsh_K'] = r_welsh_K[0:N]\n",
    "    features['Type'] = Type[0:N]\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ca9b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_probabilty(features):\n",
    "    \"\"\"\n",
    "    Predict probability for each of the 9 variable types using pre calculated features.\n",
    "    \"\"\"\n",
    "    prob={}\n",
    "    Xf = features.iloc[1] # get feature row\n",
    "    X = Xf.values # get value\n",
    "    for variable_type in label:\n",
    "        for name, clf in zip(clf_names, classifiers):\n",
    "            filename = name+'_'+variable_type+'.pkl'\n",
    "            clf = pickle.load(open(filename, 'rb'))\n",
    "            prob[variable_type] = clf.predict_proba(1)\n",
    "    return prob\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
