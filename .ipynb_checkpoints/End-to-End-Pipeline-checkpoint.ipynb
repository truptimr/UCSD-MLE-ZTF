{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c7d2285",
   "metadata": {},
   "source": [
    "## Scketch an end to end pipeline to run classification models on new data and give predictions.\n",
    "1. Get the light curve\n",
    "    1. get light curve from DR2 set\n",
    "        1. set parametes \n",
    "        1. form url using ZTF API format\n",
    "        1. query URL\n",
    "    1. get light curve from Xiao Dian's dataset\n",
    "        1. set parameters\n",
    "        1. form URL\n",
    "        1. query URL\n",
    "    1. plot flight curve per filter\n",
    "1. Calculate features\n",
    "    1. Take light curve\n",
    "    1. calaculate all features\n",
    "    1. return all features\n",
    "1. Function run all the models with data\n",
    "    1. Load all models\n",
    "    1. pass feature data to all models and get prediction proba\n",
    "    1. Return prediction proba for each classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce2699f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle # allows to save differnt trained models of the same classifier object\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2217d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_lightcurve_XD(SourceID): \n",
    "    \"\"\"\n",
    "    Download data for a single source from Xiao Dian's website. Source is identified using SourceID\n",
    "    \"\"\"\n",
    "    url = 'http://variables.cn:88/seldataz.php?SourceID=' + str(SourceID)   \n",
    "    try:\n",
    "        lc_complete = pd.read_csv(url, header='infer')\n",
    "        lc = lc_complete.drop(columns = ['SourceID','flag'])\n",
    "    except:\n",
    "        lc_complete = pd.DataFrame()\n",
    "        lc = pd.DataFrame()\n",
    "    return lc, lc_complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f071c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_lightcurve_DR(RA, Dec): \n",
    "    \"\"\"\n",
    "    Download data for a single source from DR2 dataset. Source is identified using RA and Dec location\n",
    "    \"\"\"\n",
    "    circle_radius = 0.00028 # 1 arcsec = 0.00028 degress\n",
    "    t_format = \"ipac_table\"\n",
    "    table_format = \"FORMAT=\" + str(t_format)\n",
    "    flag_mask = 32768\n",
    "    mask = \"BAD_CATFLAGS_MASK=\" + str(flag_mask)\n",
    "    collect=\"COLLECTION=\"+\"ztf_dr2\"\n",
    "    numobs = \"NOBS_MIN=20\"\n",
    "#     filter_band = \"g\"\n",
    "    label = []\n",
    "    SourceID =[]\n",
    "    start_time = time.time()\n",
    "    ra = RA\n",
    "    dec = Dec\n",
    "    circle = \"POS=CIRCLE\"+\"+\"+str(ra)+\"+\"+str(dec)+\"+\"+str(circle_radius)\n",
    "#     band = \"BANDNAME=\"+ filter_band\n",
    "    params = circle + \"&\" +  mask + \"&\" + numobs + \"&\" + collect + \"&\" + table_format\n",
    "\n",
    "    \n",
    "\n",
    "    try:\n",
    "        url= \"https://irsa.ipac.caltech.edu/cgi-bin/ZTF/nph_light_curves?\" + params\n",
    "        lc_complete = pd.read_csv(url, header=None, delim_whitespace=True, skiprows=55) # extract data\n",
    "        header = pd.read_csv(url, header=None, sep='|', skiprows=50,usecols=range(1,25), nrows=1)\n",
    "        lc_complete.columns = header.iloc[0].str.strip()\n",
    "        lc = lc_complete[['ra','dec','hjd','mag','magerr','filtercode']]\n",
    "        lc.columns=['RAdeg', 'DEdeg', 'HJD', 'mag', 'e_mag', 'band']\n",
    "        lc.loc[lc['band']=='zg']='g'\n",
    "        lc.loc[lc['band']=='zr']='r'\n",
    "    except:\n",
    "        lc_complete = pd.DataFrame()\n",
    "        lc = pd.DataFrame()\n",
    "\n",
    "    return lc, lc_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6780977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(mag,mag_err):\n",
    "    mag2 = (mag_err*mag_err) # mag err square\n",
    "    mag2_inv = 1/mag2.values; # take inverse of the values\n",
    "    w = pd.Series(mag2_inv) # covert it back to s series\n",
    "    sw = w.sum() # sum of weights\n",
    "    wmag = mag*w # multiply magnitude with weights\n",
    "    wmean = wmag.sum()/sw # weighted mean\n",
    "    return wmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b950d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# welsh J, K statistics\n",
    "def welsh_staton(mag_series,wmean):\n",
    "    N = len(mag_series)\n",
    "    d_i = N/(N-1)*(mag_series - wmean) # replace mean by weighted mean\n",
    "    d_i1 = d_i.shift(periods=-1)\n",
    "    d_i1.fillna(0, inplace = True)\n",
    "    Pi = d_i*d_i1\n",
    "    Pi_val = Pi.values\n",
    "    Psign = np.sign(Pi_val)\n",
    "    Jval = Psign*np.sqrt(np.abs(Pi_val))\n",
    "    J = np.sum(Jval) \n",
    "    K1 = abs(d_i.values)/N\n",
    "    K2 = np.sqrt(1/N*np.sum(d_i.values*d_i.values))\n",
    "    K = np.sum(K1*K2)\n",
    "    return J, K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5baae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(lc):\n",
    "    \"\"\"\n",
    "    Calculate features for a light curve passed as a dataframe.\n",
    "    \"\"\"\n",
    "    g_mean = []\n",
    "    g_wmean = [] # weighted mean\n",
    "    g_MAD = []\n",
    "    g_IQR = []\n",
    "    g_f60 = []\n",
    "    g_f70 = []\n",
    "    g_f80 = []\n",
    "    g_f90 = []\n",
    "    g_skew = []\n",
    "    g_kurtosis = []\n",
    "    g_welsh_K = []\n",
    "    g_welsh_J = []\n",
    "\n",
    "    r_mean = []\n",
    "    r_wmean = [] # weighted mean\n",
    "    r_MAD = []\n",
    "    r_IQR = []\n",
    "    r_f60 = []\n",
    "    r_f70 = []\n",
    "    r_f80 = []\n",
    "    r_f90 = []\n",
    "    r_skew = []\n",
    "    r_kurtosis = []\n",
    "    r_welsh_K = []\n",
    "    r_welsh_J = []\n",
    "    \n",
    "    if len(lc) >1:\n",
    "        \n",
    "        dfg = lc.loc[lc[\"band\"] == \"g\"]\n",
    "        dfr = lc.loc[lc[\"band\"] == \"r\"]\n",
    "        if len(dfg) > 1:\n",
    "            N = len(dfg)\n",
    "            wmean_temp = weighted_mean(dfg.mag,dfg.e_mag)\n",
    "            K_temp, J_temp =  welsh_staton(dfg.mag, wmean_temp )\n",
    "            g_mean.append(dfg.mag.mean())\n",
    "            g_wmean.append(wmean_temp) \n",
    "            deviation = abs(dfg.mag - dfg.mag.median())\n",
    "            g_MAD.append(deviation.median())\n",
    "            g_IQR.append(dfg.mag.quantile(0.75) - dfg.mag.quantile(0.25))\n",
    "            g_f60.append(dfg.mag.quantile(0.80) - dfg.mag.quantile(0.2))\n",
    "            g_f70.append(dfg.mag.quantile(0.85) - dfg.mag.quantile(0.15))\n",
    "            g_f80.append(dfg.mag.quantile(0.9) - dfg.mag.quantile(0.10))\n",
    "            g_f90.append(dfg.mag.quantile(0.95) - dfg.mag.quantile(0.05))\n",
    "            g_skew.append(dfg.mag.skew())\n",
    "            g_kurtosis.append(dfg.mag.kurtosis())\n",
    "            g_welsh_J.append(J_temp)\n",
    "            g_welsh_K.append(K_temp)\n",
    "        else:\n",
    "            g_mean.append(np.NaN)\n",
    "            g_wmean.append(np.NaN) \n",
    "            g_MAD.append(np.NaN)\n",
    "            g_IQR.append(np.NaN)\n",
    "            g_f60.append(np.NaN)\n",
    "            g_f70.append(np.NaN)\n",
    "            g_f80.append(np.NaN)\n",
    "            g_f90.append(np.NaN)\n",
    "            g_skew.append(np.NaN)\n",
    "            g_kurtosis.append(np.NaN)\n",
    "            g_welsh_J.append(np.NaN)\n",
    "            g_welsh_K.append(np.NaN)\n",
    "                \n",
    "        if len(dfr) >1:\n",
    "            N = len(dfr)\n",
    "            wmean_temp = weighted_mean(dfr.mag,dfr.e_mag)\n",
    "            K_temp, J_temp =  welsh_staton(dfr.mag, wmean_temp )\n",
    "            r_mean.append(dfr.mag.mean())\n",
    "            r_wmean.append(wmean_temp) \n",
    "            deviation = abs(dfr.mag - dfr.mag.median())\n",
    "            r_MAD.append(deviation.median())\n",
    "            r_IQR.append(dfr.mag.quantile(0.75) - dfr.mag.quantile(0.25))\n",
    "            r_f60.append(dfr.mag.quantile(0.80) - dfr.mag.quantile(0.2))\n",
    "            r_f70.append(dfr.mag.quantile(0.85) - dfr.mag.quantile(0.15))\n",
    "            r_f80.append(dfr.mag.quantile(0.9) - dfr.mag.quantile(0.10))\n",
    "            r_f90.append(dfr.mag.quantile(0.95) - dfr.mag.quantile(0.05))\n",
    "            r_skew.append(dfr.mag.skew())\n",
    "            r_kurtosis.append(dfr.mag.kurtosis())\n",
    "            r_welsh_J.append(J_temp)\n",
    "            r_welsh_K.append(K_temp)\n",
    "        else:\n",
    "            r_mean.append(np.NaN)\n",
    "            r_wmean.append(np.NaN) \n",
    "            r_MAD.append(np.NaN)\n",
    "            r_IQR.append(np.NaN)\n",
    "            r_f60.append(np.NaN)\n",
    "            r_f70.append(np.NaN)\n",
    "            r_f80.append(np.NaN)\n",
    "            r_f90.append(np.NaN)\n",
    "            r_skew.append(np.NaN)\n",
    "            r_kurtosis.append(np.NaN)\n",
    "            r_welsh_J.append(np.NaN)\n",
    "            r_welsh_K.append(np.NaN)\n",
    "\n",
    "    else:\n",
    "        g_mean.append(np.NaN)\n",
    "        g_wmean.append(np.NaN) \n",
    "        g_MAD.append(np.NaN)\n",
    "        g_IQR.append(np.NaN)\n",
    "        g_f60.append(np.NaN)\n",
    "        g_f70.append(np.NaN)\n",
    "        g_f80.append(np.NaN)\n",
    "        g_f90.append(np.NaN)\n",
    "        g_skew.append(np.NaN)\n",
    "        g_kurtosis.append(np.NaN)\n",
    "        g_welsh_J.append(np.NaN)\n",
    "        g_welsh_K.append(np.NaN)\n",
    "        r_mean.append(np.NaN)\n",
    "        r_wmean.append(np.NaN) \n",
    "        r_MAD.append(np.NaN)\n",
    "        r_IQR.append(np.NaN) \n",
    "        r_f60.append(np.NaN)\n",
    "        r_f70.append(np.NaN)\n",
    "        r_f80.append(np.NaN)\n",
    "        r_f90.append(np.NaN)\n",
    "        r_skew.append(np.NaN)\n",
    "        r_kurtosis.append(np.NaN)\n",
    "        r_welsh_J.append(np.NaN)\n",
    "        r_welsh_K.append(np.NaN)\n",
    "        \n",
    "    # del features\n",
    "    features = pd.DataFrame()\n",
    "    N = 1\n",
    "\n",
    "    # g filter data\n",
    "    features['g_mean'] = g_mean[0:N]\n",
    "    features['g_wmean'] = g_wmean[0:N]\n",
    "    features['g_MAD'] = g_MAD[0:N]\n",
    "    features['g_IQR'] = g_IQR[0:N]\n",
    "    features['g_f60'] = g_f60[0:N]\n",
    "    features['g_f70'] = g_f70[0:N]\n",
    "    features['g_f80'] = g_f80[0:N]\n",
    "    features['g_f90'] = g_f90[0:N]\n",
    "    features['g_skew'] = g_skew[0:N]\n",
    "    features['g_kurtosis'] = g_kurtosis[0:N]\n",
    "    features['g_welsh_J'] = g_welsh_J[0:N]\n",
    "    features['g_welsh_K'] = g_welsh_K[0:N]\n",
    "\n",
    "    # r filter data\n",
    "    features['r_mean'] = r_mean[0:N]\n",
    "    features['r_wmean'] = r_wmean[0:N]\n",
    "    features['r_MAD'] = r_MAD[0:N]\n",
    "    features['r_IQR'] = r_IQR[0:N]\n",
    "    features['r_f60'] = r_f60[0:N]\n",
    "    features['r_f70'] = r_f70[0:N]\n",
    "    features['r_f80'] = r_f80[0:N]\n",
    "    features['r_f90'] = r_f90[0:N]\n",
    "    features['r_skew'] = r_skew[0:N]\n",
    "    features['r_kurtosis'] = r_kurtosis[0:N]\n",
    "    features['r_welsh_J'] = r_welsh_J[0:N]\n",
    "    features['r_welsh_K'] = r_welsh_K[0:N]\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca9b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_probabilty(features):\n",
    "    \"\"\"\n",
    "    Predict probability for each of the 9 variable types using pre calculated features.\n",
    "    \"\"\"\n",
    "    prob={}\n",
    "    label = ['BYDra', 'EW', 'SR', 'RSCVN', 'RR', 'DSCT', 'EA', 'Mira', 'RRc']\n",
    "    for variable_type in label:\n",
    "        print(variable_type)\n",
    "        name = 'XGBoost'\n",
    "        filename = name+'_'+variable_type+'.pkl'\n",
    "        clf = pickle.load(open(filename, 'rb'))\n",
    "        prob[variable_type] = clf.predict_proba(features)\n",
    "    return prob\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b6af6",
   "metadata": {},
   "source": [
    "## Run whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f601af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BYDra\n",
      "EW\n",
      "SR\n",
      "RSCVN\n",
      "RR\n",
      "DSCT\n",
      "EA\n",
      "Mira\n",
      "RRc\n",
      "{'BYDra': array([[8.8995695e-04, 9.9911004e-01]], dtype=float32), 'EW': array([[0.00453466, 0.99546534]], dtype=float32), 'SR': array([[0.00564849, 0.9943515 ]], dtype=float32), 'RSCVN': array([[0.9068926 , 0.09310742]], dtype=float32), 'RR': array([[0.02155012, 0.9784499 ]], dtype=float32), 'DSCT': array([[0.290358, 0.709642]], dtype=float32), 'EA': array([[1.09910965e-04, 9.99890089e-01]], dtype=float32), 'Mira': array([[0.00724643, 0.99275357]], dtype=float32), 'RRc': array([[0.06593126, 0.93406874]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# query data\n",
    "SourceID = 487839\n",
    "lc1,lc_complete1 =  query_lightcurve_XD(SourceID)\n",
    "RA = 50.0\n",
    "Dec = 50.0\n",
    "lc2,lc_complete2 =  query_lightcurve_DR(RA, Dec)\n",
    "# calculate features\n",
    "features = calculate_features(lc2)\n",
    "# run prediction models\n",
    "prob = prediction_probabilty(features)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "419193f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g_mean</th>\n",
       "      <th>g_wmean</th>\n",
       "      <th>g_MAD</th>\n",
       "      <th>g_IQR</th>\n",
       "      <th>g_f60</th>\n",
       "      <th>g_f70</th>\n",
       "      <th>g_f80</th>\n",
       "      <th>g_f90</th>\n",
       "      <th>g_skew</th>\n",
       "      <th>g_kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th>r_MAD</th>\n",
       "      <th>r_IQR</th>\n",
       "      <th>r_f60</th>\n",
       "      <th>r_f70</th>\n",
       "      <th>r_f80</th>\n",
       "      <th>r_f90</th>\n",
       "      <th>r_skew</th>\n",
       "      <th>r_kurtosis</th>\n",
       "      <th>r_welsh_J</th>\n",
       "      <th>r_welsh_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.267203</td>\n",
       "      <td>18.265021</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.06175</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1463</td>\n",
       "      <td>-0.4976</td>\n",
       "      <td>0.557607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.04425</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>-0.031502</td>\n",
       "      <td>-0.670633</td>\n",
       "      <td>243.903481</td>\n",
       "      <td>2358.198455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      g_mean    g_wmean   g_MAD    g_IQR   g_f60   g_f70   g_f80   g_f90  \\\n",
       "0  18.267203  18.265021  0.0305  0.06175  0.0702  0.0869  0.1136  0.1463   \n",
       "\n",
       "   g_skew  g_kurtosis  ...   r_MAD    r_IQR   r_f60  r_f70   r_f80   r_f90  \\\n",
       "0 -0.4976    0.557607  ...  0.0215  0.04425  0.0534  0.061  0.0707  0.0798   \n",
       "\n",
       "     r_skew  r_kurtosis   r_welsh_J    r_welsh_K  \n",
       "0 -0.031502   -0.670633  243.903481  2358.198455  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b817b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_prob=list(prob.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e11258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9501455 0.0498545]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_prob[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537088fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
